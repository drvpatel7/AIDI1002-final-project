# -*- coding: utf-8 -*-
"""AIDI_1002_Final_Project_Template.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1kLYybssRLTANDa5RO4_XC1tJ6nJCo9

Change Model Parameters
"""

# Import libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error

from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from tensorflow.keras.optimizers import Adam

# Load dataset
url = "https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv"
df = pd.read_csv(url)
df.columns = ['Month', 'Passengers']
df['Month'] = pd.to_datetime(df['Month'])
df.set_index('Month', inplace=True)

plt.plot(df['Passengers'])
plt.title("Monthly Airline Passengers")
plt.xlabel("Time")
plt.ylabel("Passengers")
plt.show()

# Preprocessing
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(df[['Passengers']])

# Function to create sequences
def create_dataset(data, time_step=12):
    X, y = [], []
    for i in range(len(data) - time_step):
        X.append(data[i:i+time_step])
        y.append(data[i+time_step])
    return np.array(X), np.array(y)

time_step = 12
X, y = create_dataset(scaled_data, time_step)

# Reshape input to be [samples, time steps, features]
X = X.reshape(X.shape[0], X.shape[1], 1)

# Split into train, validation, test
train_size = int(len(X) * 0.7)
val_size = int(len(X) * 0.15)

X_train = X[:train_size]
y_train = y[:train_size]

X_valid = X[train_size:train_size+val_size]
y_valid = y[train_size:train_size+val_size]

X_test = X[train_size+val_size:]
y_test = y[train_size+val_size:]

# Define LSTM model with changed parameters
def create_model(timesteps):
    model = Sequential()
    model.add(LSTM(128, return_sequences=True, input_shape=(timesteps, 1), name='lstm_1'))
    model.add(Dropout(0.2))
    model.add(LSTM(32, name='lstm_2'))
    model.add(Dropout(0.2))
    model.add(Dense(1))
    model.compile(
        loss='mean_squared_error',
        optimizer=Adam(learning_rate=0.01),
        metrics=['mean_absolute_error']
    )
    return model

# Create and show model
model = create_model(timesteps=time_step)
model.summary()

# Callbacks and Training
es = EarlyStopping(monitor='val_mean_absolute_error', patience=15, verbose=1)
mc = ModelCheckpoint('best_model.h5', save_best_only=True)

fit = model.fit(
    X_train, y_train,
    batch_size=32,
    epochs=100,
    verbose=2,
    validation_data=(X_valid, y_valid),
    callbacks=[es, mc]
)

# Plot training history
fig, (axL, axR) = plt.subplots(1, 2, figsize=(14, 5))

axL.plot(fit.history['loss'], label="Train Loss (MSE)")
axL.plot(fit.history['val_loss'], label="Validation Loss (MSE)")
axL.set_title("Model Loss")
axL.set_xlabel("Epoch")
axL.set_ylabel("Loss")
axL.legend()

axR.plot(fit.history['mean_absolute_error'], label="Train MAE")
axR.plot(fit.history['val_mean_absolute_error'], label="Validation MAE")
axR.set_title("Model MAE")
axR.set_xlabel("Epoch")
axR.set_ylabel("MAE")
axR.legend()

plt.tight_layout()
plt.show()

# Evaluation
model = load_model('best_model.h5')

# Predict and inverse scale
pred_train = model.predict(X_train)
pred_valid = model.predict(X_valid)
pred_test = model.predict(X_test)

pred_train = scaler.inverse_transform(pred_train).flatten()
pred_valid = scaler.inverse_transform(pred_valid).flatten()
pred_test = scaler.inverse_transform(pred_test).flatten()

y_train_orig = scaler.inverse_transform(y_train).flatten()
y_valid_orig = scaler.inverse_transform(y_valid).flatten()
y_test_orig = scaler.inverse_transform(y_test).flatten()

# Plot predictions
plt.figure(figsize=(12, 6))
plt.plot(np.arange(len(y_train_orig)), y_train_orig, label="Train Actual")
plt.plot(np.arange(len(y_train_orig)), pred_train, label="Train Predicted")
plt.plot(np.arange(len(y_train_orig), len(y_train_orig) + len(y_valid_orig)), y_valid_orig, label="Valid Actual")
plt.plot(np.arange(len(y_train_orig), len(y_train_orig) + len(y_valid_orig)), pred_valid, label="Valid Predicted")
plt.plot(np.arange(len(y_train_orig) + len(y_valid_orig), len(y_train_orig) + len(y_valid_orig) + len(y_test_orig)), y_test_orig, label="Test Actual")
plt.plot(np.arange(len(y_train_orig) + len(y_valid_orig), len(y_train_orig) + len(y_valid_orig) + len(y_test_orig)), pred_test, label="Test Predicted")
plt.legend()
plt.title("Forecast vs Actual")
plt.xlabel("Time Index")
plt.ylabel("Passengers")
plt.show()

# Print metrics
def print_metrics(true, pred, label):
    rmse = np.sqrt(mean_squared_error(true, pred))
    mae = mean_absolute_error(true, pred)
    print(f"{label} â†’ RMSE: {rmse:.2f}, MAE: {mae:.2f}")

print_metrics(y_train_orig, pred_train, "Train")
print_metrics(y_valid_orig, pred_valid, "Validation")
print_metrics(y_test_orig, pred_test, "Test")